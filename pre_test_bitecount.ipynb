{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "30e00bfc",
   "metadata": {},
   "source": [
    "# Extract Poses into NPY Files (Mimic PoseRAC's pre_test.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a5058f16",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-07 16:09:25.098072: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-09-07 16:09:26.189204: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.2/lib64:\n",
      "2024-09-07 16:09:26.189286: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.2/lib64:\n",
      "2024-09-07 16:09:26.189293: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading DLC 2.3.10...\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "import re\n",
    "import os\n",
    "import sys\n",
    "import deeplabcut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a881f5d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# System alterations\n",
    "\n",
    "# Set the print options to avoid truncation\n",
    "np.set_printoptions(threshold=sys.maxsize) # Default threshold is 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "41a0ae8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is not an official demo dataset.\n",
      "Loaded, now creating training data...\n",
      "The training dataset is successfully created. Use the function 'train_network' to start training. Happy training!\n"
     ]
    }
   ],
   "source": [
    "# Note that parameters of this project can be seen at: *openfield-Pranav-2018-10-30/config.yaml*\n",
    "PATH_CONFIG_FILE = os.path.join(os.getcwd(), 'examples', 'CowBytes-Single-Sadat-2024-06-30', 'config.yaml')\n",
    "deeplabcut.load_demo_data(PATH_CONFIG_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7851425a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define test poses destination directory and video file paths [EDIT HERE]\n",
    "TEST_POSES_DEST_DIR = os.path.join(os.getcwd(), 'examples', 'BiteCountA_pose', 'test_poses')\n",
    "ROOT_VIDEO_DIR = os.path.join(os.getcwd(), 'examples', 'BiteCountA_pose', 'video')\n",
    "TRAIN_VIDEO_DIR = os.path.join(ROOT_VIDEO_DIR, 'train')\n",
    "VALID_VIDEO_DIR = os.path.join(ROOT_VIDEO_DIR, 'valid')\n",
    "TEST_VIDEO_DIR = os.path.join(ROOT_VIDEO_DIR, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5ab773f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create test_poses directory\n",
    "os.makedirs(TEST_POSES_DEST_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80e4bec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract poses into CSV files\n",
    "video_dir = [TRAIN_VIDEO_DIR, VALID_VIDEO_DIR, TEST_VIDEO_DIR]\n",
    "\n",
    "for dir in video_dir:\n",
    "    deeplabcut.analyze_videos(PATH_CONFIG_FILE,dir,save_as_csv=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "da70c650",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalise(datapoints, dimensions):\n",
    "    x_max = np.expand_dims(np.max(datapoints[:, 0::3], axis=1), 1)\n",
    "    x_min = np.expand_dims(np.min(datapoints[:, 0::3], axis=1), 1)\n",
    "\n",
    "    y_max = np.expand_dims(np.max(datapoints[:, 1::3], axis=1), 1)\n",
    "    y_min = np.expand_dims(np.min(datapoints[:, 1::3], axis=1), 1)\n",
    "\n",
    "    datapoints[:, 0::3] = (datapoints[:, 0::3] - x_min) / (x_max - x_min)\n",
    "    datapoints[:, 1::3] = (datapoints[:, 1::3] - y_min) / (y_max - y_min)\n",
    "\n",
    "    if dimensions == 3:\n",
    "        z_max = np.expand_dims(np.max(datapoints[:, 2::3], axis=1), 1)\n",
    "        z_min = np.expand_dims(np.min(datapoints[:, 2::3], axis=1), 1)\n",
    "        datapoints[:, 2::3] = (datapoints[:, 2::3] - z_min) / (z_max - z_min)\n",
    "    else:\n",
    "        datapoints[:, 2::3] = 0\n",
    "    return datapoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9253a50d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract depth estimations in MiDaS environment and move .pfm files to extracted directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "98ff1435",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/isl-org/MiDaS/blob/master/utils.py\n",
    "def read_pfm(path):\n",
    "    \"\"\"Read pfm file.\n",
    "\n",
    "    Args:\n",
    "        path (str): path to file\n",
    "\n",
    "    Returns:\n",
    "        tuple: (data, scale)\n",
    "    \"\"\"\n",
    "    with open(path, \"rb\") as file:\n",
    "\n",
    "        color = None\n",
    "        width = None\n",
    "        height = None\n",
    "        scale = None\n",
    "        endian = None\n",
    "\n",
    "        header = file.readline().rstrip()\n",
    "        if header.decode(\"ascii\") == \"PF\":\n",
    "            color = True\n",
    "        elif header.decode(\"ascii\") == \"Pf\":\n",
    "            color = False\n",
    "        else:\n",
    "            raise Exception(\"Not a PFM file: \" + path)\n",
    "\n",
    "        dim_match = re.match(r\"^(\\d+)\\s(\\d+)\\s$\", file.readline().decode(\"ascii\"))\n",
    "        if dim_match:\n",
    "            width, height = list(map(int, dim_match.groups()))\n",
    "        else:\n",
    "            raise Exception(\"Malformed PFM header.\")\n",
    "\n",
    "        scale = float(file.readline().decode(\"ascii\").rstrip())\n",
    "        if scale < 0:\n",
    "            # little-endian\n",
    "            endian = \"<\"\n",
    "            scale = -scale\n",
    "        else:\n",
    "            # big-endian\n",
    "            endian = \">\"\n",
    "\n",
    "        data = np.fromfile(file, endian + \"f\")\n",
    "        shape = (height, width, 3) if color else (height, width)\n",
    "\n",
    "        data = np.reshape(data, shape)\n",
    "        data = np.flipud(data)\n",
    "\n",
    "        return data, scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "62568ab1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of generated CSV Files: 14\n",
      "['/home/jason/Documents/repositories/DeepLabCut/examples/BiteCountA_pose/video/test/4ff8a74c52c529eceb817a1d89e76a3ae053583c2abc491ecacbe560484b2e7e_2DLC_resnet50_CowBytes-SingleJun30shuffle1_288000.csv', '/home/jason/Documents/repositories/DeepLabCut/examples/BiteCountA_pose/video/test/d40739c2aa4b801a2eda2bbb8a554a6ff85e3fc331b719fb52af72bf43224086_2DLC_resnet50_CowBytes-SingleJun30shuffle1_288000.csv', '/home/jason/Documents/repositories/DeepLabCut/examples/BiteCountA_pose/video/test/747419b046c70c69e41b2857b7af91465dcc0c49e0e91ca96f253da03067dd32_2DLC_resnet50_CowBytes-SingleJun30shuffle1_288000.csv', '/home/jason/Documents/repositories/DeepLabCut/examples/BiteCountA_pose/video/test/10f1a9b90589c2bc657320dc4958fb19ea2d51fbcdb251402e6112e4407de2e7_4DLC_resnet50_CowBytes-SingleJun30shuffle1_288000.csv', '/home/jason/Documents/repositories/DeepLabCut/examples/BiteCountA_pose/video/test/e151c20b878c4425ce832d2f5120a218f4e31b765ec2a352130a5a877fddd041_2DLC_resnet50_CowBytes-SingleJun30shuffle1_288000.csv']\n"
     ]
    }
   ],
   "source": [
    "# Load all generated .csv files\n",
    "csv_files = glob.glob(os.path.join(ROOT_VIDEO_DIR, '**', '*.csv'), recursive=True)\n",
    "print(\"Number of generated CSV Files:\", len(csv_files))\n",
    "print(csv_files[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "571c0d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "for csv_file in csv_files:\n",
    "    # Process CSV file contents\n",
    "    df = pd.read_csv(csv_file, header=None)\n",
    "    df = df.drop([0, 1, 2]).reset_index(drop=True)\n",
    "    df.drop(columns=df.columns[0], axis=1, inplace=True)\n",
    "    df.iloc[:, 1:] = df.iloc[:, 1:].astype(np.float32)\n",
    "    df.iloc[:, 2::3] = 0 # Set z-values to 0\n",
    "\n",
    "    # Get video name from CSV file name\n",
    "    video_name = os.path.basename(csv_file.split('DLC')[0])\n",
    "\n",
    "    # Get depth values from PFM files\n",
    "    for i, row in df.iterrows():\n",
    "        pfm_file = os.path.join(os.path.dirname(csv_file), f\"{video_name}_{str(i)}-dpt_swin2_large_384.pfm\")\n",
    "        if os.path.isfile(pfm_file):\n",
    "            data, _ = read_pfm(pfm_file)\n",
    "            x_coords = np.rint(row[0::3].to_numpy().astype(np.float32)).astype(int)\n",
    "            y_coords = np.rint(row[1::3].to_numpy().astype(np.float32)).astype(int)\n",
    "            x_coords = np.clip(x_coords, 0, data.shape[1] - 1)\n",
    "            y_coords = np.clip(y_coords, 0, data.shape[0] - 1)\n",
    "            z_values = data[y_coords, x_coords]\n",
    "            row[2::3] = z_values\n",
    "\n",
    "    datapoints = normalise(df.values.astype(np.float32), 3)\n",
    "\n",
    "    # Save NPY file with datapoints\n",
    "    dest_file = os.path.join(TEST_POSES_DEST_DIR, video_name)\n",
    "    np.save(dest_file, datapoints)\n",
    "    print(\"Created file: \", dest_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "942826f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove redundant files in video directories\n",
    "files = glob.glob(os.path.join(ROOT_VIDEO_DIR, '**', '*.*'), recursive=True)\n",
    "\n",
    "# Delete non-MP4 files\n",
    "for file in files:\n",
    "    if not file.endswith('.mp4'):\n",
    "        try:\n",
    "            os.remove(file)\n",
    "            print(f\"Deleted: {file}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error deleting {file}: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (DLC)",
   "language": "python",
   "name": "deeplabcut"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
