{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "30e00bfc",
   "metadata": {},
   "source": [
    "# Extract Poses into NPY Files (Mimic PoseRAC's pre_test.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a5058f16",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-04 22:28:41.351592: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-09-04 22:28:43.078210: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.2/lib64:\n",
      "2024-09-04 22:28:43.078312: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.2/lib64:\n",
      "2024-09-04 22:28:43.078319: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading DLC 2.3.10...\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "import sys\n",
    "import deeplabcut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a881f5d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# System alterations\n",
    "\n",
    "# Set the print options to avoid truncation\n",
    "np.set_printoptions(threshold=sys.maxsize) # Default threshold is 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "41a0ae8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is not an official demo dataset.\n",
      "Loaded, now creating training data...\n",
      "The training dataset is successfully created. Use the function 'train_network' to start training. Happy training!\n"
     ]
    }
   ],
   "source": [
    "# Note that parameters of this project can be seen at: *openfield-Pranav-2018-10-30/config.yaml*\n",
    "PATH_CONFIG_FILE = os.path.join(os.getcwd(), 'examples', 'CowBytes-Single-Sadat-2024-06-30', 'config.yaml')\n",
    "deeplabcut.load_demo_data(PATH_CONFIG_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7851425a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define test poses destination directory and video file paths [EDIT HERE]\n",
    "TEST_POSES_DEST_DIR = os.path.join(os.getcwd(), 'examples', 'BiteCountA_pose', 'test_poses')\n",
    "ROOT_VIDEO_DIR = os.path.join(os.getcwd(), 'examples', 'BiteCountA_pose', 'video')\n",
    "TRAIN_VIDEO_DIR = os.path.join(ROOT_VIDEO_DIR, 'train')\n",
    "VALID_VIDEO_DIR = os.path.join(ROOT_VIDEO_DIR, 'valid')\n",
    "TEST_VIDEO_DIR = os.path.join(ROOT_VIDEO_DIR, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5ab773f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create test_poses directory\n",
    "os.makedirs(TEST_POSES_DEST_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80e4bec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract poses into CSV files\n",
    "video_dir = [TRAIN_VIDEO_DIR, VALID_VIDEO_DIR, TEST_VIDEO_DIR]\n",
    "\n",
    "for dir in video_dir:\n",
    "    deeplabcut.analyze_videos(PATH_CONFIG_FILE,dir,save_as_csv=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "62568ab1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of generated CSV Files: 90\n",
      "['/home/jason/Documents/repositories/DeepLabCut/examples/BiteCountA_pose/video/valid/056837a2b71e7d93ad65e388dbb0c670a0a440c3ba4f88d82d728ff49d77844c_1DLC_resnet50_CowBytes-SingleJun30shuffle1_288000.csv', '/home/jason/Documents/repositories/DeepLabCut/examples/BiteCountA_pose/video/valid/117f0eeafe8d5ac58b984131dff27ba3e285203d3e3ea7d090f300f1e33b3c4b_1DLC_resnet50_CowBytes-SingleJun30shuffle1_288000.csv', '/home/jason/Documents/repositories/DeepLabCut/examples/BiteCountA_pose/video/valid/73c745847dc41f6e0c54fefcadfd13613a200d58b7073017124483409638c9be_1DLC_resnet50_CowBytes-SingleJun30shuffle1_288000.csv', '/home/jason/Documents/repositories/DeepLabCut/examples/BiteCountA_pose/video/valid/9c08225dd12cdfdfbdc00043de3d390c275458ebe07d07114df2fedb056f4e08_1DLC_resnet50_CowBytes-SingleJun30shuffle1_288000.csv', '/home/jason/Documents/repositories/DeepLabCut/examples/BiteCountA_pose/video/valid/95040dc15ce9ada82353103a13d1b395c937a9ea6747159f631bfa492b98373f_3DLC_resnet50_CowBytes-SingleJun30shuffle1_288000.csv']\n"
     ]
    }
   ],
   "source": [
    "# Load all generated .csv files\n",
    "csv_files = glob.glob(os.path.join(ROOT_VIDEO_DIR, '**', '*.csv'), recursive=True)\n",
    "print(\"Number of generated CSV Files:\", len(csv_files))\n",
    "print(csv_files[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "da70c650",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalise(datapoints, dimensions):\n",
    "    x_max = np.expand_dims(np.max(datapoints[:, 0::3], axis=1), 1)\n",
    "    x_min = np.expand_dims(np.min(datapoints[:, 0::3], axis=1), 1)\n",
    "\n",
    "    y_max = np.expand_dims(np.max(datapoints[:, 1::3], axis=1), 1)\n",
    "    y_min = np.expand_dims(np.min(datapoints[:, 1::3], axis=1), 1)\n",
    "\n",
    "    datapoints[:, 0::3] = (datapoints[:, 0::3] - x_min) / (x_max - x_min)\n",
    "    datapoints[:, 1::3] = (datapoints[:, 1::3] - y_min) / (y_max - y_min)\n",
    "\n",
    "    if dimensions == 3:\n",
    "        z_max = np.expand_dims(np.max(datapoints[:, 2::3], axis=1), 1)\n",
    "        z_min = np.expand_dims(np.max(datapoints[:, 2::3], axis=1), 1)\n",
    "        datapoints[:, 2::3] = (datapoints[:, 2::3] - z_min) / (z_max - z_min)\n",
    "    else:\n",
    "        datapoints[:, 2::3] = 0\n",
    "    return datapoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "571c0d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "for csv_file in csv_files:\n",
    "    # Process CSV file contents\n",
    "    df = pd.read_csv(csv_file, header=None)\n",
    "    df = df.drop([0, 1, 2]).reset_index(drop=True)\n",
    "    df.drop(columns=df.columns[0], axis=1, inplace=True)\n",
    "    datapoints = df.values.astype(np.float32)\n",
    "    datapoints[:, 2::3] = 0\n",
    "    datapoints = normalise(datapoints, 2)\n",
    "\n",
    "    # Save NPY file with datapoints\n",
    "    dest_file = os.path.join(TEST_POSES_DEST_DIR, os.path.basename(csv_file.split('DLC')[0]))\n",
    "    np.save(dest_file, datapoints)\n",
    "    print(\"Created file: \", dest_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "942826f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove redundant files in video directories\n",
    "files = glob.glob(os.path.join(ROOT_VIDEO_DIR, '**', '*.*'), recursive=True)\n",
    "\n",
    "# Delete non-JPG files\n",
    "for file in files:\n",
    "    if not file.endswith('.mp4'):\n",
    "        try:\n",
    "            os.remove(file)\n",
    "            print(f\"Deleted: {file}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error deleting {file}: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (DLC)",
   "language": "python",
   "name": "deeplabcut"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
